{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('social-force-env')",
   "display_name": "Python 3.7.7 64-bit ('social-force-env')",
   "metadata": {
    "interpreter": {
     "hash": "a7087ed91ab75477b5d7fa11d9ebca0347319bc75df8ebdaeb21a489660e952f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import importlib.util\n",
    "import torch\n",
    "import gym\n",
    "import copy\n",
    "import git\n",
    "import re\n",
    "from tensorboardX import SummaryWriter\n",
    "from crowd_sim.envs.utils.robot import Robot\n",
    "from crowd_nav.utils.trainer import VNRLTrainer, MPRLTrainer\n",
    "from crowd_nav.utils.memory import ReplayMemory\n",
    "from crowd_nav.utils.explorer import Explorer\n",
    "from crowd_nav.policy.policy_factory import policy_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crowd_nav.configs.icra_benchmark.config import BaseEnvConfig, BasePolicyConfig, BaseTrainConfig, Config\n",
    "\n",
    "\n",
    "class EnvConfig(BaseEnvConfig):\n",
    "    def __init__(self, debug=False):\n",
    "        super(EnvConfig, self).__init__(debug)\n",
    "        self.env.randomize_attributes = True\n",
    "        self.env.time_step = 1\n",
    "        self.sim.centralized_planning = False\n",
    "        self.sim.human_num = 8\n",
    "        self.humans.policy = \"socialforce\"\n",
    "\n",
    "\n",
    "class PolicyConfig(BasePolicyConfig):\n",
    "    def __init__(self, debug=False):\n",
    "        super(PolicyConfig, self).__init__(debug)\n",
    "        self.name = 'model_predictive_rl'\n",
    "\n",
    "        # gcn\n",
    "        self.gcn.num_layer = 2\n",
    "        self.gcn.X_dim = 32\n",
    "        self.gcn.similarity_function = 'embedded_gaussian'\n",
    "        self.gcn.layerwise_graph = False\n",
    "        self.gcn.skip_connection = True\n",
    "\n",
    "        self.model_predictive_rl = Config()\n",
    "        self.model_predictive_rl.linear_state_predictor = True\n",
    "        self.model_predictive_rl.planning_depth = 1\n",
    "        self.model_predictive_rl.planning_width = 1\n",
    "        self.model_predictive_rl.do_action_clip = False\n",
    "        self.model_predictive_rl.motion_predictor_dims = [64, 5]\n",
    "        self.model_predictive_rl.value_network_dims = [32, 100, 100, 1]\n",
    "        self.model_predictive_rl.share_graph_model = False\n",
    "\n",
    "\n",
    "class TrainConfig(BaseTrainConfig):\n",
    "    def __init__(self, debug=False):\n",
    "        super(TrainConfig, self).__init__(debug)\n",
    "\n",
    "        self.train.freeze_state_predictor = False\n",
    "        self.train.detach_state_predictor = False\n",
    "        self.train.reduce_sp_update_frequency = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure policy\n",
    "policy_config = PolicyConfig()\n",
    "policy = policy_factory[policy_config.name]()\n",
    "if not policy.trainable:\n",
    "    parser.error('Policy has to be trainable')\n",
    "policy.configure(policy_config)\n",
    "policy.set_device(0)\n",
    "\n",
    "# configure environment\n",
    "env_config = EnvConfig(True)\n",
    "env = gym.make('CrowdSim-v0')\n",
    "env.configure(env_config)\n",
    "robot = Robot(env_config, 'robot')\n",
    "robot.kinematics = \"holonomic\"\n",
    "robot.time_step = env.time_step\n",
    "env.set_robot(robot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "corner\n"
    }
   ],
   "source": [
    "env.set_scene(\"corner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[4, 3, 1]\nSpawn group 0 of size 4, center: [-7.08780388  3.48611877], goal: [ 0.41219612 -4.01388123]\n[&lt;crowd_sim.envs.utils.human.Human object at 0x7fcd194499d0&gt;, &lt;crowd_sim.envs.utils.human.Human object at 0x7fcd194490d0&gt;, &lt;crowd_sim.envs.utils.human.Human object at 0x7fcd19449c10&gt;, &lt;crowd_sim.envs.utils.human.Human object at 0x7fcd19459290&gt;]\nSpawn group 1 of size 3, center: [-0.17629283 -6.41332761], goal: [-7.67629283  1.08667239]\n[&lt;crowd_sim.envs.utils.human.Human object at 0x7fcd19459310&gt;, &lt;crowd_sim.envs.utils.human.Human object at 0x7fcd19459410&gt;, &lt;crowd_sim.envs.utils.human.Human object at 0x7fcd19459250&gt;]\nSpawn group 2 of size 1, center: [ 2.68272985 -5.30027618], goal: [-4.81727015  2.19972382]\n[&lt;crowd_sim.envs.utils.human.Human object at 0x7fcd19459890&gt;]\n"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "&#39;NoneType&#39; object has no attribute &#39;time_step&#39;",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-5-7d317680d839&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 2\u001b[0;31m \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/social_nav_ws/SocialGroupNav/crowd_sim/envs/crowd_sim.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, phase, test_case)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobot\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhumans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 215\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentralized_planning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: &#39;NoneType&#39; object has no attribute &#39;time_step&#39;"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "ob = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}